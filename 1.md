qpLLxNyWpIkgRpAsaHvHaGkTDwPHHXWupm

```bash
conda create -n mxr_kgllm python=3.10 -y
conda activate mxr_kgllm
nvcc --version
nvidia-smi

conda install cuda-toolkit=11.8 cuda-cupti=11.8 cuda-cudart=11.8 cuda-nvtx=11.8 cuda=11.8 cuda-compiler=11.8 cuda-runtime=11.8 cuda-nvprune=11.8 cuda-nvprune=11.8 cuda-libraries=11.8 -c nvidia
conda install pytorch pytorch-cuda=11.8 torchvision torchaudio -c pytorch
pip install mkl==2024

conda install huggingface_hub transformers tokenizers datasets sentence-transformers azure-identity openai wandb rich accelerate evaluate nltk rouge-score absl-py bert_score openpyxl -c conda-forge

conda activate base
conda remove --name mxr_kgllm --all -y
conda clean --all -y
```

```bash
cd /home/dingqiyang/mxr/rewrite_kblam-main
python check_gpu.py

python train_test.py --large_language_model_name meta-llama/Llama-3.2-1B-Instruct --sentence_transformer_name sentence-transformers/all-MiniLM-L6-v2 --debug False --device cuda:0 --dataset_name synthetic.json --tokenizer_padding_side left --num_epoch 10 --batch_size 10 --stopper_patience 10 --optimizer_learning_rate 0.0001 --optimizer_weight_decay 0.0001 --seed 1 --separate_query_head True --kb_layer_frequency 3 --save_model True

python train_test.py --large_language_model_name meta-llama/Llama-3.2-1B-Instruct --sentence_transformer_name sentence-transformers/all-MiniLM-L6-v2 --debug False --device cuda:2 --dataset_name synthetic.json --tokenizer_padding_side left --num_epoch 10 --batch_size 10 --stopper_patience 10 --optimizer_learning_rate 0.0001 --optimizer_weight_decay 0.0001 --seed 1 --separate_query_head True --kb_layer_frequency 3 --save_model True

CUDA_VISIBLE_DEVICES=2 nohup python train_test.py --large_language_model_name meta-llama/Llama-3.2-1B-Instruct --sentence_transformer_name sentence-transformers/all-MiniLM-L6-v2 --debug False --device cuda:2 --dataset_name synthetic.json --tokenizer_padding_side left --num_epoch 10 --batch_size 10 --stopper_patience 10 --optimizer_learning_rate 0.0001 --optimizer_weight_decay 0.0001 --seed 1 --separate_query_head True --kb_layer_frequency 3 --save_model True

CUDA_VISIBLE_DEVICES=2 nohup python train_test.py --large_language_model_name meta-llama/Llama-3.2-1B-Instruct --sentence_transformer_name sentence-transformers/all-MiniLM-L6-v2 --debug False --device cuda:0 --dataset_name synthetic.json --tokenizer_padding_side left --num_epoch 10 --batch_size 10 --stopper_patience 3 --optimizer_learning_rate 0.0001 --optimizer_weight_decay 0.0001 --seed 1 --separate_query_head True --kb_layer_frequency 3 --save_model True > output.log 2>&1 &

cat output.log


python -c "import transformers; print([d for d in dir(transformers) if "GenerationMixin" in d])"
```
